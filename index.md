## About Me

My name is Qian Qiao (ä¹”è°¦). I am currently a researcher at Soul AILab. I received my Master's degree from Soochow University in July 2025, supervised by Professors [Fanzhang Li](https://scst.suda.edu.cn/0e/e0/c11250a528096/page.htm). My previous research focused on multimodal understanding, image generation, text spotting, and few-shot learning. Additionally, I have four years of experience in blockchain technology and investment. **Currently, my primary research interests are real-time video generation and dLLMs, and I am actively seeking collaborators in these fields!**

<!-- <i style="color:#e74d3c">I will join [Weizhong Zhang](https://weizhonz.github.io/)'s team as a research assistant next year.</i>   -->

<!-- I am actively looking for a Ph.D. position or **research assistant (remote)** in 2025 Fall. Feel free to contact me if you are interested! -->
+ ğŸ“§ Email: [joeqian@aliyun.com](mailto:joeqian@aliyun.com), [qqiao@stu.suda.edu.cn](mailto:qqiao@stu.suda.edu.cn) (Since I have graduated, my academic email address will be deactivated.)
+ ğŸ’¬ Wechat: Joeqqqqqqq
+ ğŸ“± Phone: +86 18888178182

## Research and Publications
To date, I have published over **10** scholarly papers as a first author or co-author, and I have actively participated in the review process of top-tier conferences and journals such as AAAI, ACL, EMNLP, ACM MM, ICASSP and PR, among others. My work primarily focuses on areas such as multimodal understanding, image generation, text spotting and few-shot learning.

<!-- ## ğŸ“– Educations-->
<!-- + Master, School of Computer Science and Technology, **Soochow University**, Suzhou, China.-->
<!-- + Bachelor,School of Computer Science and Technology, **Soochow University**, Suzhou, China.-->
## ğŸ– Honors and Awards
<!-- - *2022.09* National Scholarships for Postgraduate Students. -->
- National Scholarship, 2024 (MS. student)
- Special Grade Scholarship, 2023 (MS. student)

## Academic Competitions
* **2024.06**: My collaborator Yu Xie and I won **three first places** and **one second place** in the **ICADR2024-Text Map** Challenge (ICADR is one of the most authoritative conferences in the field of OCR), and we have been **invited** to present a technical report at ICADR2024.

## ğŸ”¥ News
- *2025.01*: ğŸ‰ `QPruner:ProbabilisticDecision Quantization for StructuredPruning in Large Language Models` is accepted by NAACL 2025.
- *2024.12*: ğŸ‰ `AIM: Let Any Multimodal Large Language Models Embrace Efficient In-Context Learning` is accepted by AAAI 2024.
- *2024.11*: ğŸ‰ Invited by CogSci, ICME and IJCNN as Reviewer.
- *2024.10*: ğŸ‰ ğŸ”¥ğŸ”¥ğŸ”¥ I honoured the national scholarship.
- *2024.07*: ğŸ‰ Invited by AAAI as Reviewer.
- *2024.08*: ğŸ‰ One paper is accepted by PRICAI 2024.
- *2024.07*: ğŸ‰ ğŸ”¥ğŸ”¥ğŸ”¥ `DNTextSpotter: Arbitrary-Shaped Scene Text Spotting via Improved Denoising Training` is accepted by ACM MM 2024.
- *2024.07*: ğŸ‰ Invited by EMNLP as Reviewer.
- *2024.06*: ğŸ‰ Two papers are accepted by ICANN 2024.
- *2024.06*: ğŸ‰ Two papers are submitted to EMNLP 2024 as co-author.
- *2024.05*: ğŸ‰ Invited by NeurIPS as Reviewer.
- *2024.04*: ğŸ‰ Attending ICASSP2024 in Seoul, South Korea.
- *2024.04*: ğŸ‰ Two papers are accepted by ICME 2024.
- *2024.03*: ğŸ‰ Invited by MM as Program Reviewer.

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2025</div><video src="https://github.com/user-attachments/assets/e55952e6-e1b2-44a5-9887-a89307a378da" width="320" controls loop></video></div></div>
<div class='paper-box-text' markdown="1">

- Let Them Talk: Audio-Driven Multi-Person Conversational Video Generation,

  **Zhe Kong** *, Feng Gao *, Yong Zhang, Zhuoliang Kang, Xiaoming Wei, Xunliang Cai, Guanying Chen, Wenhan Luo

  *Conference on Neural Information Processing Systems (NeurIPS), 2025.*

  [**[arxiv]**](https://arxiv.org/abs/2505.22647) [**[code]**](https://github.com/MeiGen-AI/MultiTalk) [**[project]**](https://meigen-ai.github.io/multi-talk/)  [![GitHub](https://img.shields.io/github/stars/MeiGen-AI/MultiTalk?style=social)](https://github.com/MeiGen-AI/MultiTalk)


</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Technical Report</div><img src='images/paper/infinitetalk.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- InfiniteTalk: Audio-driven Video Generation for Sparse-Frame Video Dubbing,

  Shaoshu Yang *, **Zhe Kong** *, Feng Gao *, Meng Cheng *, Xiangyu Liu *, Yong Zhang, Zhuoliang Kang, Wenhan Luo, Xunliang Cai, Ran He, Xiaoming Wei

  *Technical Report, 2025.*

  [**[arxiv]**](https://arxiv.org/abs/2508.14033) [**[code]**](https://github.com/MeiGen-AI/InfiniteTalk) [**[project]**](https://meigen-ai.github.io/InfiniteTalk/)  [![GitHub](https://img.shields.io/github/stars/MeiGen-AI/InfiniteTalk?style=social)](https://github.com/MeiGen-AI/InfiniteTalk)


</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM SIGGRAPH 2025</div><img src='images/paper/dam-vsr.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- DAM-VSR: Disentanglement of Appearance and Motion for Video Super-Resolution,

  **Zhe Kong**, Le Li, Yong Zhang, Feng Gao, Shaoshu Yang, Tao Wang, Kaihao Zhang, Zhuoliang Kang, Xiaoming Wei, Guanying Chen, Wenhan Luo

  *ACM SIGGRAPH, 2025.*

  [**[arxiv]**](https://arxiv.org/abs/2507.01012)  [**[code]**](https://github.com/kongzhecn/DAM-VSR)  [**[project]**](https://kongzhecn.github.io/projects/dam-vsr/)  [![GitHub](https://img.shields.io/github/stars/kongzhecn/DAM-VSR?style=social)](https://github.com/kongzhecn/DAM-VSR)

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2024</div><img src='images/paper/omg.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- OMG: Occlusion-friendly Personalized Multi-concept Generation in Diffusion Models,

  **Zhe Kong**, Yong Zhang, Tianyu Yang, Tao Wang, Kaihao Zhang, Bizhu Wu, Guanying Chen, Wei Liu, Wenhan Luo, 

  *European Conference on Computer Vision (ECCV), 2024.*

  [**[arxiv]**](https://arxiv.org/abs/2403.10983) [**[code]**](https://github.com/kongzhecn/OMG) [**[project]**](https://kongzhecn.github.io/omg-project/) [**[huggingFace demo]**](https://huggingface.co/spaces/Fucius/OMG)  [![GitHub](https://img.shields.io/github/stars/kongzhecn/OMG?style=social)](https://github.com/kongzhecn/OMG)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TCSVT</div><img src='images/paper/DTDA.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- Dual Teacher Knowledge Distillation with Domain Alignment for Face Anti-spoofing,

  **Zhe Kong**, Wentian Zhang, Tao Wang, Kaihao Zhang, Yuexiang Li, Xiaoying Tang, Wenhan Luo,

  *IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2024.*

  [**[paper]**](https://ieeexplore.ieee.org/document/10654388) [**[arxiv]**](https://arxiv.org/abs/2401.01102)
  
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TNNLS</div><img src='images/paper/dfdm.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- Taming Self-Supervised Learning for Presentation Attack Detection: De-Folding and De-Mixing,
  
  **Zhe Kong**, Wentian Zhang, Feng Liu, Wenhan Luo, Haozhe Liu, Linlin Shen, Raghavendra Ramachandra,

  *IEEE Transactions on Neural Networks and learning systems (TNNLS), 2023.*

  [**[paper]**](https://ieeexplore.ieee.org/abstract/document/10051654) [**[arxiv]**](https://arxiv.org/abs/2109.04100) [**[code]**](https://github.com/kongzhecn/dfdm)  [![GitHub](https://img.shields.io/github/stars/kongzhecn/dfdm?style=social)](https://github.com/kongzhecn/dfdm)
  
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TIFS</div><img src='images/paper/cfd-pad.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- Fingerprint Presentation Attack Detection by Channel-Wise Feature Denoising,

  Feng Liu, **Zhe Kong**, Haozhe Liu, Wentian Zhang, Linlin Shen,

  *IEEE Transactions on Information Forensics and Security (TIFS), 2022.*

  [**[paper]**](https://ieeexplore.ieee.org/abstract/document/9851680) [**[arxiv]**](https://arxiv.org/abs/2111.07620) [**[code]**](https://github.com/kongzhecn/cfd-pad)  [![GitHub](https://img.shields.io/github/stars/kongzhecn/cfd-pad?style=social)](https://github.com/kongzhecn/cfd-pad) 
  
</div>
</div>



## Academic Services
* **Reviewer**: TCSVT, TMM, PR, ICLR, NIPS, AAAI, ACM MM, ACL-ARR, ICASSP.

## ğŸ’» Internships
* **2024.06 - now**, Research Intern, Soul APP, Shanghai, China.
* **2024.02 - 2024.05**, Research Intern, bilibili Inc, Shanghai, China.
