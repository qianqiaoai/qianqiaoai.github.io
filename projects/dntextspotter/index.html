<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Image Signal Process">
  <meta name="keywords" content="Image Signal Process, Image Compression">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DNTextSpotter: Arbitrary-Shaped Scene Text Spotting via Improved Denoising Training</title>
  <style>
    @keyframes shake {
      0% {transform: translateX(0);}
      10%, 90% {transform: translateX(-5px);}
      20%, 80% {transform: translateX(5px);}
      30%, 50%, 70% {transform: translateX(-5px);}
      40%, 60% {transform: translateX(5px);}
      100% {transform: translateX(0);}
    }

    #blur {
      /* font-size: 60px; */
      color: rgb(52,144,197);
      filter: blur(3x);
      -webkit-filter: blur(2.5px);
      animation: shake 1s infinite;
      display: inline-block;;
      clear: none;
    }
    #shake {
      /* font-size: 60px; */
      animation: shake 1s infinite;
      display: inline-block;;
      clear: none;
    }
  </style>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-QRQSXV0K5T"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-QRQSXV0K5T');
  </script>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" sizes="256x256" href="./static/image/apple.png" type="image/png"/>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/video_comparison.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <!--<div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a target="_blank" rel="noopener noreferrer" class="navbar-item" href="https://www.viclab.kaist.ac.kr">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          Related Works
        </a>
        <div class="navbar-dropdown">
          <a target="_blank" rel="noopener noreferrer" class="navbar-item" href="https://hangg7.com/dycheck/">
            Dycheck (Neurips 2022)
          </a>
          <a target="_blank" rel="noopener noreferrer" class="navbar-item" href="https://robust-dynrf.github.io/">
            RoDynRF (CVPR 2023)
          </a>
          <a target="_blank" rel="noopener noreferrer" class="navbar-item" href="https://caoang327.github.io/HexPlane/">
            HexPlane (CVPR 2023)
          </a>
          <a target="_blank" rel="noopener noreferrer" class="navbar-item" href="https://wangpeng000.github.io/BAD-NeRF/">
            BAD-NeRF (CVPR 2023)
          </a>
          <a target="_blank" rel="noopener noreferrer" class="navbar-item" href="https://dogyoonlee.github.io/dpnerf/">
            DP-NeRF (CVPR 2023)
          </a>
          <a target="_blank" rel="noopener noreferrer" class="navbar-item" href="https://jaminfong.cn/tineuvox/">
            TiNeuVox (ACM SIGGRAPH Asia 2022)
          </a>
          <a target="_blank" rel="noopener noreferrer" class="navbar-item" href="https://hypernerf.github.io/">
            HyperNeRF (ACM Trans. Graph. 2021)
          </a>
          <a target="_blank" rel="noopener noreferrer" class="navbar-item" href="https://nerfies.github.io/">
            Nerfies (ICCV 2021)
          </a>
          <a target="_blank" rel="noopener noreferrer" class="navbar-item" href="https://www.cs.cornell.edu/~zl548/NSFF/">
            NSFF (CVPR 2021)
          </a>
        </div>
      </div>
    </div>

  </div>-->
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <div class="title is-2 publication-title">
            <h1 style="display: inline; clear:none;">
                  <!-- 图标 -->
                  <!-- <img src="./static/image/apple.png" width="40", height="40"> -->
                  <font color="#d91421"><b>DNTextSpotter:</b></font> Arbitrary-Shaped Scene Text Spotting via Improved Denoising Training
              </h1>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a rel="noopener noreferrer" href="https://qianqiaoai.github.io/">Yu Xie</a><sup>1,2,*</sup></span>,
            <span class="author-block">
              <a rel="noopener noreferrer" href="https://qianqiaoai.github.io/">Qian Qiao</a><sup>1,2,*</sup>,
            </span>
            <span class="author-block">
              <!-- target="_blank"  -->
              <a rel="noopener noreferrer" href="https://scholar.google.com/citations?hl=en&user=9vR57s8AAAAJ">Jun Gao</a><sup>1</sup>, 
            </span>
            <span class="author-block">
              <a rel="noopener noreferrer" href="https://dblp.uni-trier.de/pid/258/3154.html">Tianxiang Wu</a><sup>1</sup>, 
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=CM--ILcAAAAJ&hl=en&oi=ao">Shaoyao Huang</a><sup>1</sup>, 
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=eJ_g_u4doHYC">Jiaqing Fan</a><sup>1,†</sup>, 
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?view_op=new_profile&hl=zh-CN">Ziqiang Cao</a><sup>1</sup>, 
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=E9zWgmwAAAAJ">Zili Wang</a><sup>3</sup>, 
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=06ITfcEAAAAJ">Zhang Yue</a><sup>1</sup>, 
            </span>
            <span class="author-block">
              <a href="https://dblp.uni-trier.de/pid/232/1783.html">Huyang Sun</a><sup>2</sup>, 
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=O4wOcbwAAAAJ&hl=en&oi=ao">Jielei Zhang</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Soochow University, </span>
            <span class="author-block"><sup>2</sup>bilibili Inc, </span>
            <span class="author-block"><sup>3</sup>Inf Tech.</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal author, </span>
            <span class="author-block"><sup>†</sup>Corresponding author. </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a target="_blank" rel="noopener noreferrer" href="./DNTextSpotter.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a target="_blank" rel="noopener noreferrer" href="https://qianqiaoai.github.io/projects/dntextspotter/realcamnet.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Arxiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a target="_blank" rel="noopener noreferrer" href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a target="_blank" rel="noopener noreferrer" href="https://github.com/yyyyyxie/DNTextSpotter/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- <section class="section">
  <div class="container is-widescreen">
    <h2 class="title is-3">Graphical Abstract</h2>
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <image src="./static/image/graphabstract.png" class="img-responsive" alt="realcamnet_graphical_abstract"><br>
        <div class="content has-text-justified">
          <p>
            <b>Top:</b> Compared with previous methods, our approach takes into account multiple complex distortions.. <br>
          </p>
        </div>
      </div>
    </div>
  </div>
</section> -->


<script>
bulmaCarousel.attach('#results-carousel', {
  slidesToShow: 2,
  loop: true,
  pagination: false,
});
</script>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            More and more end-to-end text spotting methods based on Transformer architecture have demonstrated superior performance. These methods utilize a bipartite graph matching algorithm to perform one-to-one optimal matching between predicted objects and actual objects. However, the instability of bipartite graph matching can lead to inconsistent optimization targets, thereby affecting the training performance of the model. Existing literature applies denoising training to solve the problem of bipartite graph matching instability in object detection tasks. Unfortunately, this denoising training method cannot be directly applied to text spotting tasks, as these tasks need to perform irregular shape detection tasks and more complex text recognition tasks than classification. To address this issue, we propose a novel denoising training method (DNTextSpotter) for arbitrary-shaped text spotting. Specifically, we decompose the queries of the denoising part into noised positional queries and noised content queries. We use the four Bezier control points of the Bezier center curve to generate the noised positional queries. For the noised content queries, considering that the output of the text in a fixed positional order is not conducive to aligning position with content, we employ a masked character sliding method to initialize noised content queries, thereby assisting in the alignment of text content and position.
          </p>

          <p>

          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.bilibili.com/video/BV1tT42117t4/"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>




<section class="section">
  <div class="container is-widescreen">
    <h2 class="title is-3">Network Architecture</h2>
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <image src="./static/image/networkarch.png" class="img-responsive" alt="realcamnet_network_architecture"><br>
        <div class="content has-text-justified">
          <p>
            <b>DNTextSpotter:</b> The overall framework of DNTextSpotter. The model utilizes a backbone and an encoder to extract multi-scale features. The queries of the decoder can be divided into two parts: a matching part and a denoising part. The queries in the matching part are randomly initialized queries.
    The noised queries of denoising part can be found in Noised Positional Queries and Noised Content Queries. After decoder and task-specific head, the matching part calculates loss through a bipartite graph matching algorithm, and the denoising part calculates loss directly with the ground truth.<br>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-widescreen">
    <h2 class="title is-3">Noised Positional Queries & Noised Content Queries</h2>
    <div class="columns is-centered has-text-centered">
      <div class="column is-half">
        <figure class="image is-fullwidth">
          <img src="./static/image/mask.png" alt="realcamnet_coordinate_related_distortion">
          <figcaption class="has-text-justified">
            <p><b>Noised Positional Queries:</b> We generate noised positional queries using four Bezier control points from the ground truth, which includes uniformly sampling points along the Bezier curve, position embedding, and a two-layer MLP.</p>
          </figcaption>
        </figure>
      </div>
      <div class="column is-half">
        <figure class="image is-fullwidth">
          <img src="./static/image/content.png" alt="Second Image Description">
          <figcaption class="has-text-justified">
            <p><b>Noised Content Queries:</b> This image shows the process of generating noised content queries from the ground-truth texts. "Ø" indicates the characters will be masked, while "σ" denotes flipping the characters into any character.</p>
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-widescreen">
    <h2 class="title is-3">Rate-Distortion Curve Results</h2>
    <div class="columns is-centered has-text-centered">
      <div class="column is-half">
        <figure class="image is-fullwidth">
          <img src="./static/image/vs.png" alt="realcamnet_coordinate_related_distortion">
          <figcaption class="has-text-justified">
            <p>
              The convergence curves of DNTextSpotter (Ours), DeepSolo, TESTR, and ESTextSpotter on the Inverse-Text dataset using the ResNet-50 backbone in the 'None' results, where 'None' denotes the F1-measure without lexicon.
            </p>          
          </figcaption>
        </figure>
      </div>
      <div class="column is-half">
        <figure class="image is-fullwidth">
          <img src="./static/image/is.png" alt="Second Image Description">
          <figcaption class="has-text-justified">
            <p>For the IS of TESTR, DeepSolo, and DNTextSpotter, we trained for 120k steps under the same settings, calculating the IS at every consecutive 10k step interval.</p>
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
  </section>

  <section class="section">
    <div class="container is-widescreen">
      <h2 class="title is-3">Experiment results</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <image src="./static/image/result.png" class="img-responsive" alt="realcamnet_quantitative_results"><br>
          <div class="content has-text-justified">
            <p>
              Performances on Total-Text and CTW1500 with different backbone. E2E denotes the end-to-end spotting results. "None" denotes lexicon-free. "Full" denotes the inclusion of all words present in the test dataset. The top three scores are shown in bold <font color="#ff0000">red</font>, <font color="#0070c0">blue</font>, and <font color="#00b050">green</font> fonts. Additionally, results without TextOCR in pre-training are indicated with "*".
            </p>
          </div>
        </div>
      </div>
    </div>
    </section>


    <section class="section">
      <div class="container is-widescreen">
        <h2 class="title is-3">Visual Comparison Results</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column is-full">
            <image src="./static/image/visual.jpg" class="img-responsive" alt="realcamnet_quantitative_results"><br>
            <div class="content has-text-justified">
              <p>
                Several instance examples: rows display ESTextSpotter, DeepSolo, and DNTextSpotter (Ours) visualizations, respectively. In the recognition results, <font color="#0070c0">blue</font> within parentheses represents correct recognition, while <font color="#ff0000">red</font> denotes incorrect ones; outside the parentheses, Ø signifies no detection or no recognition took place. Additional visual analysis is provided in the paper.
              </p>
            </div>
          </div>
        </div>
      </div>
      </section>



<section class="section">
  <div class="container is-widescreen">
    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Acknowledgements</h2>

        <div class="content has-text-justified">
          <p>
            We would like to thank Ziqiang Cao and Zili Wang for providing us with 4 days of GPU usage, which allowed us to run and find the best set of parameters.
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-widescreen content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{qiao2024dntextspotter,
  title={DNTextSpotter: Arbitrary-Shaped Scene Text Spotting via Improved Denoising Training},
  author={Qiao, Qian and Xie, Yu and Gao, Jun and Wu, Tianxiang and Huang, Shaoyao and Fan, Jiaqing and Cao, Ziqiang and Wang, Zili and Zhang, Yue},
  booktitle={ACM Multimedia 2024}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a target="_blank" rel="noopener noreferrer" class="icon-link"
         href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a target="_blank" rel="noopener noreferrer" class="icon-link" href="https://github.com/yyyyyxie/DNTextSpotter/" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            We thank the authors of <a target="_blank" rel="noopener noreferrer" href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>  that kindly open sourced the template of this website.
            Please visit our <a target="_blank" rel="noopener noreferrer" href="https://qianqiaoai.github.io/">LAB</a> for more interesting researches.
          </p>
        </div>
      </div>
      <a href="https://mapmyvisitors.com/web/1bw9o"  title="Visit tracker"><img src="https://mapmyvisitors.com/map.png?d=xTEslr4Jl7NlkRcmESn9AwHdBuKFsQhpG-Gt5GAW8W4&cl=ffffff" /></a>
    </div>
  </div>
</footer>
</body>
</html>
